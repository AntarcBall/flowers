Following our discussion on the core logic and technical specifications, here is the detailed **English Pseudocode for Part 1: Semantic Parameter Mapping**.

This module ensures that any 3D coordinate from your filtered 어휘 우주 (Lexicon Universe) is deterministically mapped to a unique set of flower parameters, covering the entire possible "morphological space" (surjection).

---

## Part 1. Specification: Semantic Parameter Mapping

### 1.1 Goal

Convert a 3D position vector  into a 5-dimensional genetic parameter set  for the flower generation algorithm.

---

### 1.2 English Pseudocode

```typescript
// Define the target ranges for the flower parameters as per flower.html
STRUCTURE FlowerParameterRanges {
    m: [2.0, 12.0],       // Petal symmetry/count
    n1: [0.5, 10.0],      // Base shape complexity
    n2: [0.5, 10.0],      // Curvature A
    n3: [0.5, 10.0],      // Curvature B
    rot: [0, Math.PI * 2] // Rotation in radians
}

CLASS SemanticMapper {
    // Fixed deterministic seeds (Weights) to ensure the same star always yields the same flower
    CONSTANT SEEDS = {
        m:   { freq: [1.3, 2.7, 3.1], phase: [0.1, 0.5, 0.8] },
        n1:  { freq: [2.1, 1.4, 4.2], phase: [0.3, 0.2, 0.9] },
        n2:  { freq: [1.7, 3.3, 1.1], phase: [0.7, 0.4, 0.2] },
        n3:  { freq: [3.9, 2.5, 1.9], phase: [0.5, 0.8, 0.1] },
        rot: { freq: [0.8, 4.1, 2.3], phase: [0.2, 0.6, 0.4] }
    }

    /**
     * Maps 3D coordinates to a surjective 5D parameter space
     * @param x, y, z: Coordinates from the filtered 3D embedding space ([-L, L])
     */
    FUNCTION mapCoordinatesToParams(x, y, z) {
        // 1. Normalize input coordinates to [-1, 1] based on cube size L
        normalizedX = x / L
        normalizedY = y / L
        normalizedZ = z / L

        // 2. Apply a Sum-of-Sines transformation for each parameter
        // This ensures a smooth, deterministic, and surjective distribution
        params = {}
        FOR EACH key IN FlowerParameterRanges {
            seed = SEEDS[key]
            
            // Calculate raw wave value using superposition
            // val = sin(f1*x + p1) + sin(f2*y + p2) + sin(f3*z + p3)
            rawVal = sin(seed.freq[0] * normalizedX + seed.phase[0]) +
                     sin(seed.freq[1] * normalizedY + seed.phase[1]) +
                     sin(seed.freq[2] * normalizedZ + seed.phase[2])

            // 3. Normalize rawVal (which is in range [-3, 3]) to [0, 1]
            t = (rawVal + 3) / 6

            // 4. Interpolate (Lerp) into the specific parameter range
            range = FlowerParameterRanges[key]
            params[key] = range.min + t * (range.max - range.min)
        }

        RETURN params
    }
}

```

---

### 1.3 Mathematical Formulation for Implementation

To ensure the mapping is **Surjective (전사)** and the parameter space is filled uniformly, we use the following equation for each parameter :

Where:

*  is the -th component of the normalized 3D vector.
*  are high-frequency weights that prevent linear clustering.
*  are phase offsets to break symmetry between parameters.

---

### 1.4 Expected Outcome

* **Continuity:** Small movements in the 3D space lead to smooth changes in the flower's shape.
* **Determinism:** The same word (coordinate) always produces the exact same flower type across sessions.
* **Coverage:** Every possible flower shape within the defined `FlowerParameterRanges` can be generated by at least one coordinate in the 3D space.

Would you like me to proceed with the **English Pseudocode for Part 2 (TPS Spaceship Physics and Camera Controller)**, or should we refine the mapping logic further?
Moving to the "pilot’s seat" of your project—this part is where the user experience truly takes shape. Since we are aiming for **100% inertia** and a **TPS-style perspective**, we need a system that handles state integration (Position, Velocity, Rotation) while keeping the camera smoothly tethered to the ship.

Here is the **English Pseudocode for Part 2: TPS Spaceship Physics and Camera Controller**.

---

## Part 2. Specification: TPS Spaceship Physics & Camera Controller

### 2.1 Goal

Implement a momentum-based flight system where the spaceship's orientation dictates the direction of travel, controlled via a 3rd-person perspective.

---

### 2.2 English Pseudocode

```typescript
// Physical Constants
CONSTANT MAX_SPEED = V_max          // Defined by 20s to cross Cube L
CONSTANT ACCEL_ROT = 0.02           // How fast rotation speeds up
CONSTANT DAMPING_ROT = 0.98         // Slight friction for rotation control
CONSTANT CUBE_SIZE = L              // Boundary limit

CLASS SpaceshipController {
    // Physical State
    position = Vector3(0, 0, 0)
    quaternion = Quaternion()       // Current orientation
    
    // Momentum State
    speed = 0                       // Current scalar speed
    angularVelocity = { pitch: 0, yaw: 0 } // Rotation momentum
    
    FUNCTION update(deltaTime, inputs) {
        // 1. Speed Control (Q/E)
        IF inputs.pressed('Q') THEN speed += accel_speed
        IF inputs.pressed('E') THEN speed -= accel_speed
        speed = clamp(speed, 0, MAX_SPEED)

        // 2. Angular Momentum (WASD) - 100% Inertia
        IF inputs.pressed('W') THEN angularVelocity.pitch += ACCEL_ROT
        IF inputs.pressed('S') THEN angularVelocity.pitch -= ACCEL_ROT
        IF inputs.pressed('A') THEN angularVelocity.yaw   += ACCEL_ROT
        IF inputs.pressed('D') THEN angularVelocity.yaw   -= ACCEL_ROT
        
        // Note: No damping for speed (100% inertia), 
        // but optional slight damping for rotation helps playability
        // angularVelocity *= DAMPING_ROT 

        // 3. Update Rotation (Quaternion Math)
        pitchQuaternion = fromAxisAngle(Vector3(1, 0, 0), angularVelocity.pitch)
        yawQuaternion = fromAxisAngle(Vector3(0, 1, 0), angularVelocity.yaw)
        
        // Combine rotations: current * local changes
        this.quaternion.multiply(pitchQuaternion).multiply(yawQuaternion)

        // 4. Update Position
        // Move in the direction the ship is currently facing
        forwardVector = Vector3(0, 0, 1).applyQuaternion(this.quaternion)
        this.position.addScaledVector(forwardVector, speed * deltaTime)

        // 5. Boundary Warp Logic
        IF abs(this.position.x) > CUBE_SIZE OR 
           abs(this.position.y) > CUBE_SIZE OR 
           abs(this.position.z) > CUBE_SIZE THEN
           this.position.set(0, 0, 0) // Warp to center
        
        // 6. Update Visual Mesh
        spaceshipMesh.position.copy(this.position)
        spaceshipMesh.quaternion.copy(this.quaternion)
    }
}

```

### 2.3 TPS Camera Follow Logic

To achieve the TPS feel, the camera must not be a direct child of the spaceship (to avoid "shaky" or "stiff" movement), but rather follow it with a target offset.

```typescript
CLASS TPSCamera {
    offset = Vector3(0, 5, -15) // Behind and slightly above
    
    FUNCTION update(spaceship) {
        // 1. Calculate the ideal camera position in world space
        // Rotate the offset by the ship's current orientation
        relativeOffset = offset.clone().applyQuaternion(spaceship.quaternion)
        targetCameraPos = spaceship.position.clone().add(relativeOffset)
        
        // 2. Smoothly interpolate (Lerp) to the target position
        // This creates a "lagging" effect that feels more cinematic
        camera.position.lerp(targetCameraPos, 0.1)
        
        // 3. Always look at a point slightly ahead of the ship
        lookTarget = spaceship.position.clone().add(
            Vector3(0, 0, 10).applyQuaternion(spaceship.quaternion)
        )
        camera.lookAt(lookTarget)
    }
}

```

---

## 2.4 Implementation Notes

* **Rotation Order:** When multiplying Quaternions, the order matters. Using `localQuaternion.multiply(delta)` vs `delta.multiply(localQuaternion)` determines if you rotate relative to the ship's local axes or the world axes. For a flight sim, **local axes** (Pitch/Yaw relative to where the nose is pointing) is correct.
* **Warp Visuals:** When the warp to  happens, the camera's `lerp` might cause a massive "snap" across the screen. You should add a flag to `camera.position.copy()` (not lerp) for exactly one frame during a warp.
* **Optimization:** Since you are rendering 10k stars (even filtered), ensure the `InstancedMesh` matrices are updated only when the checkpoint changes, while the individual star "Selection Glow" (the 50% brightness) is handled via an attribute in the shader.

---

**Would you like me to move on to Part 3 (2D Garden Interaction & Absolute Coordinate Persistence), or should we look at the Python Preprocessing script for the GloVe embeddings first?**
This final part of the core specification focuses on the transition from the 3D cosmic exploration to the 2D creative output. This module handles the "landing" of your data into a persistent, scrollable, and generative garden.

---

## Part 3. Specification: 2D Garden Interaction & Persistence

### 3.1 Goal

Manage a square  world where flowers are permanently placed based on 3D selections. This includes 2D world-space scrolling and atomic data saving.

---

### 3.2 English Pseudocode

```typescript
// Configuration
CONSTANT GARDEN_SIZE = a            // Square side length
CONSTANT SCROLL_SPEED = 5.0         // WASD scrolling speed
CONSTANT FLOWER_JSON_PATH = "./db/garden.json"

CLASS GardenManager {
    camera = OrthographicCamera()
    flowers = []                    // List of placed Flower objects
    
    // State when entering from Space
    selectedStarData = null         // { color, params } from Part 1

    FUNCTION init() {
        // Setup 2D view: Camera looks down at the XY plane
        camera.position.set(GARDEN_SIZE/2, GARDEN_SIZE/2, 100)
        camera.lookAt(GARDEN_SIZE/2, GARDEN_SIZE/2, 0)
        
        // Load existing garden from local persistence
        this.flowers = PersistenceService.load()
    }

    FUNCTION update(deltaTime, inputs) {
        // 1. WASD Scrolling (World Space Navigation)
        IF inputs.pressed('W') THEN camera.position.y += SCROLL_SPEED
        IF inputs.pressed('S') THEN camera.position.y -= SCROLL_SPEED
        IF inputs.pressed('A') THEN camera.position.x -= SCROLL_SPEED
        IF inputs.pressed('D') THEN camera.position.x += SCROLL_SPEED
        
        // 2. Clamp camera to garden boundaries
        camera.position.x = clamp(camera.position.x, 0, GARDEN_SIZE)
        camera.position.y = clamp(camera.position.y, 0, GARDEN_SIZE)

        // 3. Planting Logic (Crosshair Interaction)
        IF plantingModeActive {
            // Project mouse screen position to Garden World Space
            worldPos = unprojectMouseToWorld(inputs.mouse, camera)
            crosshair.position.set(worldPos.x, worldPos.y, 1)

            IF inputs.clicked() {
                this.plantFlower(worldPos, this.selectedStarData)
            }
        }
    }

    FUNCTION plantFlower(position, data) {
        newFlower = {
            id: generateUUID(),
            x: position.x,
            y: position.y,
            color: data.color,
            params: data.params,
            timestamp: Date.now()
        }
        
        this.flowers.push(newFlower)
        renderFlowerInGarden(newFlower) // Call flower.html logic
        
        // Atomic Save
        PersistenceService.save(this.flowers)
        
        // Exit to main view
        this.exitPlantingMode()
    }
}

```

---

### 3.3 Persistence & Page Transition Logic

Since you are moving from **Space (3D)** to **Garden (2D)**, the application state must be handed over cleanly.

```typescript
CLASS AppStateManager {
    FUNCTION onStarSelected(star) {
        // 1. Trigger Part 1 Mapping
        flowerParams = SemanticMapper.map(star.pos)
        
        // 2. Store selection and fade out SpaceScene
        currentSelection = { color: star.color, params: flowerParams }
        UIManager.transitionTo("GARDEN")
        
        // 3. Initialize Garden with selection
        GardenManager.enterPlantingMode(currentSelection)
    }
}

```

---

### 3.4 Data Integrity (Local Persistence)

To prevent data corruption during the atomic write (as we discussed in the pre-report stage), use the **Temporary Write** strategy.

1. **Serialize:** Convert the `flowers` array to a JSON string.
2. **Temp Write:** Write to `garden_temp.json`.
3. **Swap:** Rename `garden_temp.json` to `garden.json`. This ensures that even if the laptop loses power, you either have the old version or the new version, but never a half-written file.

---

## 🏁 Summary of Technical Architecture

| Module | Core Responsibility | Key Math/Logic |
| --- | --- | --- |
| **Part 1** | Coordinate Translation | Multi-frequency Sine Mapping (Surjection) |
| **Part 2** | Navigation | 100% Inertia Physics & TPS Camera Lerp |
| **Part 3** | Interaction | Orthographic Projection & Atomic Persistence |

The blueprint is now complete across all three parts. You have a mathematically rigorous mapping system, a high-fidelity flight simulator, and a persistent generative art gallery.

**Would you like me to generate the first "boilerplate" code for any specific part?** I could start with the **Three.js TPS Controller (Part 2)** or the **Python Preprocessing Script** to filter your GloVe embeddings.